{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split # function for splitting data to train and test sets\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "'exec(%matplotlib inline)'\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.getcwd()+\"/input/Sentiment_GOP.csv\", encoding = \"ISO-8859-1\")\n",
    "data = data[['text','sentiment']]\n",
    "\n",
    "# Splitting the dataset into train and test set\n",
    "train, test = train_test_split(data,test_size = 0.1)\n",
    "# Removing neutral sentiments\n",
    "train = train[train.sentiment != \"Neutral\"]\n",
    "test = test[test.sentiment != \"Neutral\"]\n",
    "\n",
    "train_pos = train[ train['sentiment'] == 'Positive']\n",
    "train_pos = train_pos['text']\n",
    "train_neg = train[ train['sentiment'] == 'Negative']\n",
    "train_neg = train_neg['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "stopwords_set = set(stopwords.words(\"english\")) #stopwords are words like is, are, that\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    words_filtered = [e.lower() for e in tknzr.tokenize(row.text) if len(e) >= 3] #gets rid of words that are shorter than 3\n",
    "    words_cleaned = [word for word in words_filtered\n",
    "        if 'http' not in word\n",
    "        and not word.startswith('@')\n",
    "        and not word.startswith('#')\n",
    "        and word != 'RT']   #gets rid of words with http, @, #, or RT\n",
    "    words_without_stopwords = [word for word in words_cleaned if not word in stopwords_set]  #gets rid of stopwords\n",
    "    tweets.append((words_without_stopwords, row.sentiment))\n",
    "    \n",
    "\n",
    "test_pos = test[ test['sentiment'] == 'Positive']\n",
    "test_pos = test_pos['text']\n",
    "test_neg = test[ test['sentiment'] == 'Negative']\n",
    "test_neg = test_neg['text']\n",
    "test_set = test['text']\n",
    "test_ans = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting word features\n",
    "\n",
    "#returns list of all words\n",
    "def get_words_in_tweets(tweets):\n",
    "    all = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        all.extend(words)\n",
    "    return all \n",
    "\n",
    "#\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)   \n",
    "    #FreqDist is a class that is like dictionary with word as key and # of times it appears as value\n",
    "\n",
    "    features = wordlist.keys()\n",
    "    return features\n",
    "\n",
    "w_features = get_word_features(get_words_in_tweets(tweets)) #All unique words in all tweets\n",
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)  #document was list of words, now list of unique words\n",
    "    features = {}\n",
    "    for word in w_features:\n",
    "        features['contains(%s)' % word] = (word in document_words) #adds word from all unique words into features if that word is in document\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0))>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features,tweets)\n",
    "classifier = nltk.classify.SklearnClassifier(LinearSVC())\n",
    "classifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyScore(correct, total):\n",
    "    return correct/total      #How likely that u answer right\n",
    "\n",
    "def sensitivityScore(truePos, totalPos):\n",
    "    return truePos/totalPos    #How likely detect positive when is positive\n",
    "    \n",
    "def specificityScore(trueNeg, totalNeg):\n",
    "    return trueNeg/totalNeg   #How likely detect negative when is negative\n",
    "    \n",
    "def precisionScore(truePos, guessedPos):\n",
    "    return truePos/guessedPos #How likely is positive when detect positive\n",
    "\n",
    "def f1Score(sensitivity, precision):\n",
    "    return 2*sensitivity*precision/(sensitivity+precision)  \n",
    "    #weighted avg of recall and precision, useful if harm of falsePos and falseNeg differs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trueNeg = 0\n",
    "# truePos = 0\n",
    "# falseNeg = 0\n",
    "# falsePos = 0\n",
    "\n",
    "# #Detecting Negatives\n",
    "# wrongNeg = []\n",
    "# count = 0\n",
    "# for obj in test_neg: \n",
    "#     processedObj = extract_features(nltk.word_tokenize(obj))\n",
    "#     res =  classifier.classify(processedObj)\n",
    "#     if(res == 'Negative'): \n",
    "#         trueNeg+=1\n",
    "#     else:\n",
    "#         falsePos+=1\n",
    "#         if(count<20):\n",
    "#             count+=1\n",
    "#             wrongNeg.append(processedObj)\n",
    "        \n",
    "# #Detecting Positives\n",
    "# wrongPos = []\n",
    "# count = 0\n",
    "# for obj in test_pos:\n",
    "#     processedObj = extract_features(nltk.word_tokenize(obj))\n",
    "#     res =  classifier.classify(processedObj)\n",
    "#     if(res == 'Positive'): \n",
    "#         truePos+=1\n",
    "#     else:\n",
    "#         falseNeg+=1\n",
    "#         if(count<20):\n",
    "#             count+=1\n",
    "#             wrongPos.append(processedObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueNeg = 0\n",
    "truePos = 0\n",
    "falseNeg = 0\n",
    "falsePos = 0\n",
    "\n",
    "wrongNeg = []\n",
    "wrongPos = []\n",
    "for obj, ans in zip(test_set, test_ans): \n",
    "    res =  classifier.classify(extract_features(tknzr.tokenize(obj)))\n",
    "    if(ans == 'Negative'):\n",
    "        if(res == 'Negative'): \n",
    "            trueNeg+=1\n",
    "        else:\n",
    "            falsePos+=1\n",
    "            if(len(wrongNeg)<10):\n",
    "                wrongNeg.append([obj, ans])        \n",
    "    else:\n",
    "        if(res == 'Positive'): \n",
    "            truePos+=1\n",
    "        else:\n",
    "            falseNeg+=1\n",
    "            if(len(wrongPos)<10):\n",
    "                wrongPos.append([obj, ans])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 129\n",
      "66 781\n",
      "0.817244611059044\n",
      "0.41363636363636364\n",
      "0.922077922077922\n",
      "0.5796178343949044\n",
      "0.48275862068965514\n"
     ]
    }
   ],
   "source": [
    "print(str(truePos)+\" \"+ str(falseNeg))       \n",
    "print(str(falsePos)+ \" \"+ str(trueNeg))  \n",
    "\n",
    "accuracy = accuracyScore(truePos+trueNeg, truePos+trueNeg+falsePos+falseNeg)\n",
    "sensitivity = sensitivityScore(truePos,truePos+falseNeg)\n",
    "specificity = specificityScore(trueNeg, trueNeg+falsePos)\n",
    "precision = precisionScore(truePos, truePos+falsePos)\n",
    "f1 = f1Score(sensitivity, precision)\n",
    "\n",
    "print(accuracy)\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Local talk radio in LA is the best the morning after a presidential debate. #GOPDebate', 'Negative']\n",
      "\n",
      "\n",
      "['RT @RWSurferGirl: @tedcruz and @realDonaldTrump need to take control of this debate,  they can do it, _Ùà¼_Ùàü #GOPDebate  #GOPDebates', 'Negative']\n",
      "\n",
      "\n",
      "['Wait- Ben Carson is actually in these debates? What does he do in his downtime? I hope he brought a book. #GOPDebates', 'Negative']\n",
      "\n",
      "\n",
      "[\"#Liberals care more about Rosie O'Donnell than actually watchin the whole #GOPDebate\", 'Negative']\n",
      "\n",
      "\n",
      "['\"Remember, whatever you do, don\\'t say that you agree with Dr. Carson....Ah Fuck!!!\"-Christie\\'s debate coach. #GOPDebates', 'Negative']\n",
      "\n",
      "\n",
      "['RT @HRC: .@JohnKasich said he\\x89Ûªd love his daughters if they were gay, but his voting record says otherwise #GOPDebate http://t.co/qWNQMbLZ5d', 'Negative']\n",
      "\n",
      "\n",
      "[\"#GOPDebate well, if #Trump wins, most latino voters will vote democrat for a while, won't they?\", 'Negative']\n",
      "\n",
      "\n",
      "['RT @RadioFreeTom: Trump\\'s answer on his businesses so far is the certifiable disaster of the night, right after his \"I buy influence\" comme\\x89Û_', 'Negative']\n",
      "\n",
      "\n",
      "['Carly Fiorina wrote an op-ed for us at IJReview after her performance last night.  http://t.co/LdQE8KG2ZW #GOPDebate', 'Negative']\n",
      "\n",
      "\n",
      "['RT @Elb3001: #GOPDebate screw you @GovMikeHuckabee look up @TheLadyValor and see how transgender ppl serve this country in our military!', 'Negative']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for obj in wrongNeg:\n",
    "    print(obj)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"RT @RWSurferGirl: These debates will raise @realDonaldTrump 's ratings because Fox News is afraid of Trump and it shows. #GOPDebate #GOPDeb\\x89Û_\", 'Positive']\n",
      "\n",
      "\n",
      "[\"Jeb Bush and Rand Paul were the only ones to see their odds rise during the #GOPDebates though Bush's price was trimmed by the end.\", 'Positive']\n",
      "\n",
      "\n",
      "['@megynkelly Did @CandyCrowley coach you for last nights #GOPDebate ? @FoxNews @realDonaldTrump', 'Positive']\n",
      "\n",
      "\n",
      "['Marco Rubio debating like a champ. #partyofthefuture #GOPDebate', 'Positive']\n",
      "\n",
      "\n",
      "[\"Yeah, I'm sticking with independent. #GOPDebate #GOPPrimary\", 'Positive']\n",
      "\n",
      "\n",
      "[\"Thanks Fox News, you're raising @realDonaldTrump 's ratings. _Ùà¼_Ùàü #GOPDebate  #GOPDebates\", 'Positive']\n",
      "\n",
      "\n",
      "['.@realDonaldTrump just gave a master class on how to get away with sexism http://t.co/36sdQbY52A via @voxdotcom #GOPDebate', 'Positive']\n",
      "\n",
      "\n",
      "['RT @alexandraheuser: NYT Lib take on #GOPDebate On support4 Trump audience @ NY beer hall \\x89ÛÏIn a room full of progressives, u better believe\\x89Û_', 'Positive']\n",
      "\n",
      "\n",
      "[\"RT @RWSurferGirl: Thanks Fox News, you're raising @realDonaldTrump 's ratings. _Ùà¼_Ùàü #GOPDebate  #GOPDebates\", 'Positive']\n",
      "\n",
      "\n",
      "['Walker walks that #BlackLivesMatter  question pretty  decently #GOPDebates', 'Positive']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for obj in wrongPos:\n",
    "    print(obj)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
