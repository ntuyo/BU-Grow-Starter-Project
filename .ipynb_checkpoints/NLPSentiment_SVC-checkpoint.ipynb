{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split # function for splitting data to train and test sets\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "'exec(%matplotlib inline)'\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.getcwd()+\"/input/Sentiment_GOP.csv\", encoding = \"ISO-8859-1\")\n",
    "data = data[['text','sentiment']]\n",
    "\n",
    "# Splitting the dataset into train and test set\n",
    "train, test = train_test_split(data,test_size = 0.1)\n",
    "# Removing neutral sentiments\n",
    "train = train[train.sentiment != \"Neutral\"]\n",
    "test = test[test.sentiment != \"Neutral\"]\n",
    "\n",
    "train_pos = train[ train['sentiment'] == 'Positive']\n",
    "train_pos = train_pos['text']\n",
    "train_neg = train[ train['sentiment'] == 'Negative']\n",
    "train_neg = train_neg['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "stopwords_set = set(stopwords.words(\"english\")) #stopwords are words like is, are, that\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    words_filtered = [e.lower() for e in tknzr.tokenize(row.text) if len(e) >= 3] #gets rid of words that are shorter than 3\n",
    "    words_cleaned = [word for word in words_filtered\n",
    "        if 'http' not in word\n",
    "        and not word.startswith('@')\n",
    "        and not word.startswith('#')\n",
    "        and word != 'RT']   #gets rid of words with http, @, #, or RT\n",
    "    words_without_stopwords = [word for word in words_cleaned if not word in stopwords_set]  #gets rid of stopwords\n",
    "    tweets.append((words_without_stopwords, row.sentiment))\n",
    "    \n",
    "\n",
    "test_pos = test[ test['sentiment'] == 'Positive']\n",
    "test_pos = test_pos['text']\n",
    "test_neg = test[ test['sentiment'] == 'Negative']\n",
    "test_neg = test_neg['text']\n",
    "test_set = test['text']\n",
    "test_ans = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting word features\n",
    "\n",
    "#returns list of all words\n",
    "def get_words_in_tweets(tweets):\n",
    "    all = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        all.extend(words)\n",
    "    return all \n",
    "\n",
    "#\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)   \n",
    "    #FreqDist is a class that is like dictionary with word as key and # of times it appears as value\n",
    "\n",
    "    features = wordlist.keys()\n",
    "    return features\n",
    "\n",
    "w_features = get_word_features(get_words_in_tweets(tweets)) #All unique words in all tweets\n",
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)  #document was list of words, now list of unique words\n",
    "    features = {}\n",
    "    for word in w_features:\n",
    "        features['contains(%s)' % word] = (word in document_words) #adds word from all unique words into features if that word is in document\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False))>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features,tweets)\n",
    "classifier = nltk.classify.SklearnClassifier(SVC())\n",
    "classifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyScore(correct, total):\n",
    "    if total == 0:\n",
    "        return -1\n",
    "    return correct/total      #How likely that u answer right\n",
    "\n",
    "def sensitivityScore(truePos, totalPos):\n",
    "    if totalPos == 0:\n",
    "        return -1\n",
    "    return truePos/totalPos    #How likely detect positive when is positive\n",
    "    \n",
    "def specificityScore(trueNeg, totalNeg):\n",
    "    if totalNeg == 0:\n",
    "        return -1\n",
    "    return trueNeg/totalNeg   #How likely detect negative when is negative\n",
    "    \n",
    "def precisionScore(truePos, guessedPos):\n",
    "    if guessedPos == 0:\n",
    "        return -1\n",
    "    return truePos/guessedPos #How likely is positive when detect positive\n",
    "\n",
    "def f1Score(sensitivity, precision):\n",
    "    if (sensitivity+precision) == 0:\n",
    "        return -1\n",
    "    return 2*sensitivity*precision/(sensitivity+precision)  \n",
    "    #weighted avg of recall and precision, useful if harm of falsePos and falseNeg differs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trueNeg = 0\n",
    "# truePos = 0\n",
    "# falseNeg = 0\n",
    "# falsePos = 0\n",
    "\n",
    "# #Detecting Negatives\n",
    "# wrongNeg = []\n",
    "# count = 0\n",
    "# for obj in test_neg: \n",
    "#     processedObj = extract_features(nltk.word_tokenize(obj))\n",
    "#     res =  classifier.classify(processedObj)\n",
    "#     if(res == 'Negative'): \n",
    "#         trueNeg+=1\n",
    "#     else:\n",
    "#         falsePos+=1\n",
    "#         if(count<20):\n",
    "#             count+=1\n",
    "#             wrongNeg.append(processedObj)\n",
    "        \n",
    "# #Detecting Positives\n",
    "# wrongPos = []\n",
    "# count = 0\n",
    "# for obj in test_pos:\n",
    "#     processedObj = extract_features(nltk.word_tokenize(obj))\n",
    "#     res =  classifier.classify(processedObj)\n",
    "#     if(res == 'Positive'): \n",
    "#         truePos+=1\n",
    "#     else:\n",
    "#         falseNeg+=1\n",
    "#         if(count<20):\n",
    "#             count+=1\n",
    "#             wrongPos.append(processedObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueNeg = 0\n",
    "truePos = 0\n",
    "falseNeg = 0\n",
    "falsePos = 0\n",
    "\n",
    "wrongNeg = []\n",
    "wrongPos = []\n",
    "for obj, ans in zip(test_set, test_ans): \n",
    "    res =  classifier.classify(extract_features(tknzr.tokenize(obj)))\n",
    "    if(ans == 'Negative'):\n",
    "        if(res == 'Negative'): \n",
    "            trueNeg+=1\n",
    "        else:\n",
    "            falsePos+=1\n",
    "            if(len(wrongNeg)<10):\n",
    "                wrongNeg.append([obj, ans])        \n",
    "    else:\n",
    "        if(res == 'Positive'): \n",
    "            truePos+=1\n",
    "        else:\n",
    "            falseNeg+=1\n",
    "            if(len(wrongPos)<10):\n",
    "                wrongPos.append([obj, ans])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 226\n",
      "0 854\n",
      "0.7907407407407407\n",
      "0.0\n",
      "1.0\n",
      "-1\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(str(truePos)+\" \"+ str(falseNeg))       \n",
    "print(str(falsePos)+ \" \"+ str(trueNeg))  \n",
    "\n",
    "accuracy = accuracyScore(truePos+trueNeg, truePos+trueNeg+falsePos+falseNeg)\n",
    "sensitivity = sensitivityScore(truePos,truePos+falseNeg)\n",
    "specificity = specificityScore(trueNeg, trueNeg+falsePos)\n",
    "precision = precisionScore(truePos, truePos+falsePos)\n",
    "f1 = f1Score(sensitivity, precision)\n",
    "\n",
    "print(accuracy)\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in wrongNeg:\n",
    "    print(obj)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in wrongPos:\n",
    "    print(obj)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
